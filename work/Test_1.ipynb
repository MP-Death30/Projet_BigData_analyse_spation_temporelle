{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a2ff7b-e8e9-4ece-aa3f-881d890abb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ DÃ©marrage de l'ETL Spark...\n",
      "   ðŸ“ Traitement du GeoJSON...\n",
      "   ðŸ’¨ Traitement Air Quality (Mode Manuel)...\n",
      "   ðŸ”— Jointure Air Quality + GÃ©ographie...\n",
      "   â˜€ï¸  Traitement MÃ©tÃ©o...\n",
      "âœ… ETL terminÃ© ! Fichiers gÃ©nÃ©rÃ©s.\n",
      "\n",
      "ðŸš€ Application gÃ©nÃ©rÃ©e ! Lancez dans le terminal : streamlit run app.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date, col, lit, substring, regexp_replace\n",
    "from pyspark.sql.types import DoubleType, StructType, StructField, StringType\n",
    "\n",
    "# ==============================================================================\n",
    "# Ã‰TAPE 1 : PRÃ‰PARATION DES DONNÃ‰ES (ETL SPARK)\n",
    "# ==============================================================================\n",
    "print(\"ðŸ”„ DÃ©marrage de l'ETL Spark...\")\n",
    "\n",
    "# 1. Initialisation Spark\n",
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    spark = SparkSession.builder.appName(\"OneCode_ETL\").getOrCreate()\n",
    "\n",
    "# 2. Configuration des chemins\n",
    "GEOJSON_URL = \"https://raw.githubusercontent.com/nycehs/NYC_geography/master/UHF42.geo.json\"\n",
    "AIR_QUALITY_PATH = \"/home/jovyan/work/data/air_quality/nyc_air_quality_raw.json\" \n",
    "WEATHER_PATH = \"hdfs://namenode:9000/user/mathis/datalake/noaa_gsod_nyc_raw_2005_2023.parquet\"\n",
    "\n",
    "# --- A. Traitement GÃ©ographique (GeoJSON) ---\n",
    "print(\"   ðŸ“ Traitement du GeoJSON...\")\n",
    "gdf_quartiers = gpd.read_file(GEOJSON_URL)\n",
    "\n",
    "# Correction GÃ©omÃ©trique : On projette en EPSG:2263 (NYC Feet) pour calculer le centre, puis on revient en Lat/Lon\n",
    "# Cela Ã©vite le warning et donne un centre plus prÃ©cis.\n",
    "gdf_quartiers = gdf_quartiers.to_crs(epsg=2263) \n",
    "gdf_quartiers['centroid'] = gdf_quartiers.geometry.centroid\n",
    "gdf_quartiers = gdf_quartiers.to_crs(epsg=4326) # Retour au standard GPS\n",
    "\n",
    "# Extraction Lat/Lon des centroÃ¯des recalculÃ©s\n",
    "# Attention: AprÃ¨s reprojection, on accÃ¨de au centroid via la colonne qu'on a crÃ©Ã©e, mais il faut la reprojeter aussi\n",
    "# Plus simple : on recrÃ©e le centroid en 4326 directement si la prÃ©cision au mÃ¨tre n'est pas vitale, \n",
    "# mais pour Ãªtre propre, utilisons la colonne geometry reprojetÃ©e.\n",
    "gdf_quartiers['LATITUDE_ZONE'] = gdf_quartiers['centroid'].to_crs(epsg=4326).y\n",
    "gdf_quartiers['LONGITUDE_ZONE'] = gdf_quartiers['centroid'].to_crs(epsg=4326).x\n",
    "\n",
    "# Sauvegardes\n",
    "gdf_quartiers[['GEOCODE', 'GEONAME', 'BOROUGH', 'geometry']].to_file(\"dashboard_map.geojson\", driver='GeoJSON')\n",
    "pdf_locations = pd.DataFrame(gdf_quartiers[['GEOCODE', 'GEONAME', 'LATITUDE_ZONE', 'LONGITUDE_ZONE']])\n",
    "spark_locations = spark.createDataFrame(pdf_locations)\n",
    "\n",
    "# --- B. Traitement Air Quality (CORRIGÃ‰) ---\n",
    "print(\"   ðŸ’¨ Traitement Air Quality (Mode Manuel)...\")\n",
    "\n",
    "# Lecture manuelle car le JSON est une liste de listes (Socrata)\n",
    "with open(AIR_QUALITY_PATH, 'r') as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# DÃ©finition du SchÃ©ma explicite (Index Socrata)\n",
    "# 17=Date, 14=GeoID, 10=Polluant, 18=Valeur\n",
    "fields = []\n",
    "for i in range(20): # On crÃ©e 20 colonnes gÃ©nÃ©riques\n",
    "    name = f\"col_{i}\"\n",
    "    if i == 17: name = \"DATE_MESURE_BRUTE\"\n",
    "    elif i == 14: name = \"GEOJOIN_ID_BRUT\"\n",
    "    elif i == 10: name = \"NOM_POLLUANT\"\n",
    "    elif i == 18: name = \"VALEUR_MESURE_BRUTE\"\n",
    "    fields.append(StructField(name, StringType(), True))\n",
    "\n",
    "schema = StructType(fields)\n",
    "\n",
    "# CrÃ©ation DataFrame Spark\n",
    "air_q_df = spark.createDataFrame(raw_data, schema=schema)\n",
    "\n",
    "# Nettoyage\n",
    "air_quality_clean = air_q_df.withColumn(\n",
    "    \"DATE_OBSERVATION\", \n",
    "    to_date(col(\"DATE_MESURE_BRUTE\"))\n",
    ").select(\n",
    "    col(\"GEOJOIN_ID_BRUT\").alias(\"GEOJOIN_ID\"),\n",
    "    col(\"DATE_OBSERVATION\"),\n",
    "    col(\"NOM_POLLUANT\"),\n",
    "    col(\"VALEUR_MESURE_BRUTE\").cast(DoubleType()).alias(\"VALEUR\")\n",
    ").filter(col(\"VALEUR\").isNotNull())\n",
    "\n",
    "# --- C. Jointure Air Quality + CoordonnÃ©es ---\n",
    "print(\"   ðŸ”— Jointure Air Quality + GÃ©ographie...\")\n",
    "final_air_data = air_quality_clean.join(\n",
    "    spark_locations,\n",
    "    air_quality_clean.GEOJOIN_ID == spark_locations.GEOCODE,\n",
    "    \"inner\"\n",
    ").drop(\"GEOCODE\")\n",
    "\n",
    "final_air_data.toPandas().to_parquet(\"dashboard_data_air.parquet\", index=False)\n",
    "\n",
    "# --- D. Traitement MÃ©tÃ©o ---\n",
    "print(\"   â˜€ï¸  Traitement MÃ©tÃ©o...\")\n",
    "weather_df = spark.read.parquet(WEATHER_PATH)\n",
    "weather_lite = weather_df.select(\"ID_STATION\", \"NAME\", \"LATITUDE\", \"LONGITUDE\", \"DATE\", \"TEMP\", \"DEWP\", \"WDSP\")\n",
    "weather_lite.toPandas().to_parquet(\"dashboard_data_weather.parquet\", index=False)\n",
    "\n",
    "print(\"âœ… ETL terminÃ© ! Fichiers gÃ©nÃ©rÃ©s.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# Ã‰TAPE 2 : GÃ‰NÃ‰RATION DU DASHBOARD (Identique)\n",
    "# ==============================================================================\n",
    "dashboard_code = \"\"\"\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from streamlit_folium import st_folium\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "st.set_page_config(layout=\"wide\", page_title=\"NYC Environmental Dashboard\")\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    geo = gpd.read_file(\"dashboard_map.geojson\")\n",
    "    air = pd.read_parquet(\"dashboard_data_air.parquet\")\n",
    "    weather = pd.read_parquet(\"dashboard_data_weather.parquet\")\n",
    "    \n",
    "    air['DATE_OBSERVATION'] = pd.to_datetime(air['DATE_OBSERVATION'])\n",
    "    weather['DATE'] = pd.to_datetime(weather['DATE'])\n",
    "    \n",
    "    stations = weather[['ID_STATION', 'NAME', 'LATITUDE', 'LONGITUDE']].drop_duplicates()\n",
    "    return geo, air, weather, stations\n",
    "\n",
    "def haversine_dist(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    a = sin((lat2-lat1)/2)**2 + cos(lat1) * cos(lat2) * sin((lon2-lon1)/2)**2\n",
    "    return 6371 * 2 * asin(sqrt(a))\n",
    "\n",
    "def get_weighted_weather(target_lat, target_lon, weather_df, station_ids):\n",
    "    subset = weather_df[weather_df['ID_STATION'].isin(station_ids)].copy()\n",
    "    if subset.empty: return None\n",
    "    subset['dist'] = subset.apply(lambda x: haversine_dist(target_lon, target_lat, x['LONGITUDE'], x['LATITUDE']), axis=1)\n",
    "    subset['weight'] = 1 / (subset['dist'] + 0.1)\n",
    "    try:\n",
    "        return np.average(subset['TEMP'], weights=subset['weight'])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "geo, df_air, df_weather, df_stations = load_data()\n",
    "\n",
    "st.sidebar.title(\"Filtres\")\n",
    "dates = st.sidebar.date_input(\"PÃ©riode\", [df_air['DATE_OBSERVATION'].min(), df_air['DATE_OBSERVATION'].max()])\n",
    "polluant = st.sidebar.selectbox(\"Polluant\", df_air['NOM_POLLUANT'].unique())\n",
    "\n",
    "mask_air = (df_air['DATE_OBSERVATION'].dt.date >= dates[0]) & (df_air['DATE_OBSERVATION'].dt.date <= dates[1])\n",
    "df_air_view = df_air[mask_air & (df_air['NOM_POLLUANT'] == polluant)]\n",
    "\n",
    "col_map, col_stats = st.columns([3, 2])\n",
    "\n",
    "with col_map:\n",
    "    st.subheader(\"Carte des Quartiers\")\n",
    "    m = folium.Map([40.7, -74.0], zoom_start=10)\n",
    "    folium.GeoJson(\n",
    "        geo, \n",
    "        name=\"Quartiers\",\n",
    "        tooltip=folium.GeoJsonTooltip(fields=['GEONAME', 'BOROUGH']),\n",
    "        style_function=lambda x: {'fillColor': '#3388ff', 'color': 'black', 'weight': 0.5, 'fillOpacity': 0.4},\n",
    "        highlight_function=lambda x: {'weight': 3, 'color': 'red'}\n",
    "    ).add_to(m)\n",
    "    st_map = st_folium(m, width=None, height=600)\n",
    "\n",
    "selected_geocode = None\n",
    "selected_name = st.sidebar.selectbox(\"Ou choisir un quartier :\", geo['GEONAME'].unique())\n",
    "q_data = geo[geo['GEONAME'] == selected_name].iloc[0]\n",
    "selected_geocode = q_data['GEOCODE']\n",
    "centroid = q_data.geometry.centroid\n",
    "lat_q, lon_q = centroid.y, centroid.x\n",
    "\n",
    "with col_stats:\n",
    "    st.title(selected_name)\n",
    "    st.info(f\"Borough: {q_data['BOROUGH']}\")\n",
    "    \n",
    "    st.markdown(\"### 1. QualitÃ© de l'Air\")\n",
    "    local_air = df_air_view[df_air_view['GEOJOIN_ID'] == selected_geocode]\n",
    "    if not local_air.empty:\n",
    "        st.metric(f\"Moyenne {polluant}\", f\"{local_air['VALEUR'].mean():.2f}\")\n",
    "        fig = px.bar(local_air, x='DATE_OBSERVATION', y='VALEUR', title=\"Ã‰volution\")\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    else:\n",
    "        st.warning(\"Pas de donnÃ©es.\")\n",
    "\n",
    "    st.markdown(\"### 2. MÃ©tÃ©o PondÃ©rÃ©e\")\n",
    "    df_stations['dist'] = df_stations.apply(lambda x: haversine_dist(lon_q, lat_q, x['LONGITUDE'], x['LATITUDE']), axis=1)\n",
    "    df_stations = df_stations.sort_values('dist')\n",
    "    sel_stations = st.multiselect(\"Stations\", df_stations['ID_STATION'].tolist(), format_func=lambda x: f\"{df_stations[df_stations.ID_STATION==x].iloc[0]['NAME']} ({df_stations[df_stations.ID_STATION==x].iloc[0]['dist']:.1f}km)\")\n",
    "    \n",
    "    if sel_stations:\n",
    "        mask_w = (df_weather['DATE'].dt.date >= dates[0]) & (df_weather['DATE'].dt.date <= dates[1])\n",
    "        w_temp = get_weighted_weather(lat_q, lon_q, df_weather[mask_w], sel_stations)\n",
    "        if w_temp: st.metric(\"TempÃ©rature PondÃ©rÃ©e\", f\"{w_temp:.1f} Â°F\")\n",
    "\"\"\"\n",
    "\n",
    "with open(\"app.py\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(dashboard_code)\n",
    "\n",
    "print(\"\\nðŸš€ Application gÃ©nÃ©rÃ©e ! Lancez dans le terminal : streamlit run app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e01da-98d2-4cce-b39c-84548c35611d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
